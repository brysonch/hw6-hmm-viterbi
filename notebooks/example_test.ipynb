{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8065f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class HiddenMarkovModel:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_states: np.ndarray, hidden_states: np.ndarray, prior_probabilities: np.ndarray, transition_probabilities: np.ndarray, emission_probabilities: np.ndarray):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            observation_states (np.ndarray): _description_\n",
    "            hidden_states (np.ndarray): _description_\n",
    "            prior_probabilities (np.ndarray): _description_\n",
    "            transition_probabilities (np.ndarray): _description_\n",
    "            emission_probabilities (np.ndarray): _description_\n",
    "        \"\"\"             \n",
    "        self.observation_states = observation_states\n",
    "        self.observation_states_dict = {observation_state: observation_state_index \\\n",
    "                                  for observation_state_index, observation_state in enumerate(list(self.observation_states))}\n",
    "\n",
    "        self.hidden_states = hidden_states\n",
    "        self.hidden_states_dict = {hidden_state_index: hidden_state \\\n",
    "                                   for hidden_state_index, hidden_state in enumerate(list(self.hidden_states))}\n",
    "        \n",
    "\n",
    "        self.prior_probabilities= prior_probabilities\n",
    "        self.transition_probabilities = transition_probabilities\n",
    "        self.emission_probabilities = emission_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7328d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "class ViterbiAlgorithm:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"    \n",
    "\n",
    "    def __init__(self, hmm_object):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            hmm_object (_type_): _description_\n",
    "        \"\"\"              \n",
    "        self.hmm_object = hmm_object\n",
    "\n",
    "    def best_hidden_state_sequence(self, decode_observation_states: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            decode_observation_states (np.ndarray): _description_\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: _description_\n",
    "        \"\"\"        \n",
    "        \n",
    "        obs_st = self.hmm_object.observation_states\n",
    "        obs_st_dict = self.hmm_object.observation_states_dict\n",
    "        hid_st = self.hmm_object.hidden_states\n",
    "        hid_st_dict = self.hmm_object.hidden_states_dict\n",
    "        prior_probs = self.hmm_object.prior_probabilities\n",
    "        emit_probs = self.hmm_object.emission_probabilities\n",
    "        trans_probs = self.hmm_object.transition_probabilities\n",
    "\n",
    "        # Initialize path (i.e., np.arrays) to store the hidden sequence states returning the maximum probability\n",
    "        path = np.zeros((len(decode_observation_states), \n",
    "                         len(self.hmm_object.hidden_states)))\n",
    "        path[0,:] = [hidden_state_index for hidden_state_index in range(len(self.hmm_object.hidden_states))]\n",
    "\n",
    "        best_path = np.zeros(len(decode_observation_states)) \n",
    "        \n",
    "        \n",
    "        # Compute initial delta:\n",
    "        # 1. Calculate the product of the prior and emission probabilities. This will be used to decode the first observation state.\n",
    "        # 2. Scale\n",
    "        init_ind = obs_st_dict[decode_observation_states[0]]\n",
    "        delta = np.multiply(prior_probs, emit_probs.T[init_ind,:])\n",
    "        #delta = delta / np.sum(delta)\n",
    "        best_path[0] = path[0, np.argmax(delta)]\n",
    "\n",
    "        # For each observation state to decode, select the hidden state sequence with the highest probability (i.e., Viterbi trellis)\n",
    "        for trellis_node in range(1, len(decode_observation_states)):\n",
    "\n",
    "            # TODO: comment the initialization, recursion, and termination steps\n",
    "\n",
    "            current_obs = obs_st_dict[decode_observation_states[trellis_node]]\n",
    "\n",
    "            product_of_delta_and_transition_emission = np.multiply(delta, trans_probs.T)\n",
    "            product_of_delta_and_transition_emission = np.multiply(product_of_delta_and_transition_emission, emit_probs[:,current_obs])\n",
    "            \n",
    "\n",
    "            # Select the hidden state sequence with the maximum probability\n",
    "            max_hidden_ind = np.argmax(product_of_delta_and_transition_emission, axis=1) \n",
    "            max_hidden = np.max(product_of_delta_and_transition_emission, axis=1)\n",
    "            print(\"max: \", max_hidden)\n",
    "            \n",
    "            path[trellis_node,:] = max_hidden_ind\n",
    "            best_path[trellis_node - 1] = np.argmax(max_hidden)\n",
    "\n",
    "            # Update best path\n",
    "            #for hidden_state in range(len(self.hmm_object.hidden_states)):\n",
    "            #    hid_st_dict[hidden_state]\n",
    "            #    np.append(best_hidden_state_path, hidden_s)\n",
    "                #path.append(max_hidden_ind)\n",
    "            #    best_path[trellis_node] = max_hidden_ind\n",
    "            #    print(\"trellis: \", path[trellis_node - 1, max_hidden_ind])\n",
    "            #    best_path[trellis_node - 1] = path[trellis_node - 1, max_hidden_ind]\n",
    "                \n",
    "            \n",
    "            # Update delta and scale\n",
    "            delta = np.multiply(prior_probs, emit_probs.T[current_obs,:])\n",
    "            #delta = delta / np.sum(delta)\n",
    "            \n",
    "            # Set best hidden state sequence in the best_path np.ndarray THEN copy the best_path to path\n",
    "\n",
    "        # Select the last hidden state, given the best path (i.e., maximum probability)\n",
    "        #best_hidden_state_path = np.array([])\n",
    "        best_hidden_state_path = best_path\n",
    "        \n",
    "        return best_hidden_state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5ff1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_case_one():\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    # index annotation observation_states=[i,j]    \n",
    "    observation_states = ['on-time','late'] \n",
    "\n",
    "    # index annotation hidden_states=[i,j]\n",
    "    hidden_states = ['no-traffic','traffic']\n",
    "\n",
    "    # PONDERING QUESTION: How would a user define/compute their own HMM instantiation inputs to decode the hidden states for their use case observations?\n",
    "    use_case_one_data = np.load('/Users/brysonchoy/Documents/hw6-hmm-viterbi/data/UserCase-One.npz')\n",
    "\n",
    "    # Instantiate submodule class models.HiddenMarkovModel with\n",
    "    # observation and hidden states and prior, transition, and emission probabilities.\n",
    "    use_case_one_hmm = HiddenMarkovModel(observation_states,\n",
    "                                         hidden_states,\n",
    "                      use_case_one_data['prior_probabilities'], # prior probabilities of hidden states in the order specified in the hidden_states list\n",
    "                      use_case_one_data['transition_probabilities'], # transition_probabilities[:,hidden_states[i]]\n",
    "                      use_case_one_data['emission_probabilities']) # emission_probabilities[hidden_states[i],:][:,observation_states[j]]\n",
    "    \n",
    "    # Instantiate submodule class models.ViterbiAlgorithm using the use case one HMM \n",
    "    use_case_one_viterbi = ViterbiAlgorithm(use_case_one_hmm)\n",
    "\n",
    "     # Check if use case one HiddenMarkovAlgorithm instance is inherited in the subsequent ViterbiAlgorithm instance\n",
    "    #assert use_case_one_viterbi.hmm_object.observation_states == use_case_one_hmm.observation_states\n",
    "    #assert use_case_one_viterbi.hmm_object.hidden_states == use_case_one_hmm.hidden_states\n",
    "\n",
    "    #assert np.allclose(use_case_one_viterbi.hmm_object.prior_probabilities, use_case_one_hmm.prior_probabilities)\n",
    "    #assert np.allclose(use_case_one_viterbi.hmm_object.transition_probabilities, use_case_one_hmm.transition_probabilities)\n",
    "    #assert np.allclose(use_case_one_viterbi.hmm_object.emission_probabilities, use_case_one_hmm.emission_probabilities)\n",
    "\n",
    "    # TODO: Check HMM dimensions and ViterbiAlgorithm\n",
    "    \n",
    "    # Find the best hidden state path for our observation states\n",
    "    use_case_decoded_hidden_states = use_case_one_viterbi.best_hidden_state_sequence(use_case_one_data['observation_states'])\n",
    "    print(\"viterbi case: \", use_case_decoded_hidden_states)\n",
    "\n",
    "    #assert np.alltrue(use_case_decoded_hidden_states == use_case_one_data['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99c3a0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  [0.34304 0.08576]\n",
      "max:  [0.08576 0.04752]\n",
      "max:  [0.04752 0.07128]\n",
      "max:  [0.04752 0.07128]\n",
      "max:  [0.08576 0.04752]\n",
      "viterbi case:  [0. 0. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "test_user_case_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc7765b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0254071",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,:] = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84f3d0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e383b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.append(x,[4,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ea346d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1., 1., 4., 4., 4.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dda0e248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1., 1., 4., 4., 4., 8.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(tr, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2f17f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
