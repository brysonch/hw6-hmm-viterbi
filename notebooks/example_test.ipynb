{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0306fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class HiddenMarkovModel:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_states: np.ndarray, hidden_states: np.ndarray, prior_probabilities: np.ndarray, transition_probabilities: np.ndarray, emission_probabilities: np.ndarray):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            observation_states (np.ndarray): _description_\n",
    "            hidden_states (np.ndarray): _description_\n",
    "            prior_probabilities (np.ndarray): _description_\n",
    "            transition_probabilities (np.ndarray): _description_\n",
    "            emission_probabilities (np.ndarray): _description_\n",
    "        \"\"\"             \n",
    "        self.observation_states = observation_states\n",
    "        self.observation_states_dict = {observation_state: observation_state_index \\\n",
    "                                  for observation_state_index, observation_state in enumerate(list(self.observation_states))}\n",
    "\n",
    "        self.hidden_states = hidden_states\n",
    "        self.hidden_states_dict = {hidden_state_index: hidden_state \\\n",
    "                                   for hidden_state_index, hidden_state in enumerate(list(self.hidden_states))}\n",
    "        \n",
    "\n",
    "        self.prior_probabilities= prior_probabilities\n",
    "        self.transition_probabilities = transition_probabilities\n",
    "        self.emission_probabilities = emission_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5bb79216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "class ViterbiAlgorithm:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"    \n",
    "\n",
    "    def __init__(self, hmm_object):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            hmm_object (_type_): _description_\n",
    "        \"\"\"              \n",
    "        self.hmm_object = hmm_object\n",
    "\n",
    "    def best_hidden_state_sequence(self, decode_observation_states: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            decode_observation_states (np.ndarray): _description_\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: _description_\n",
    "        \"\"\"        \n",
    "        \n",
    "        obs_st = self.hmm_object.observation_states\n",
    "        obs_st_dict = self.hmm_object.observation_states_dict\n",
    "        hid_st = self.hmm_object.hidden_states\n",
    "        hid_st_dict = self.hmm_object.hidden_states_dict\n",
    "        prior_probs = self.hmm_object.prior_probabilities\n",
    "        emit_probs = self.hmm_object.emission_probabilities\n",
    "        trans_probs = self.hmm_object.transition_probabilities\n",
    "\n",
    "        # Initialize path (i.e., np.arrays) to store the hidden sequence states returning the maximum probability\n",
    "        path = np.zeros((len(decode_observation_states), \n",
    "                         len(self.hmm_object.hidden_states)))\n",
    "        path[0,:] = [hidden_state_index for hidden_state_index in range(len(self.hmm_object.hidden_states))]\n",
    "\n",
    "        best_path = np.zeros(len(decode_observation_states)) \n",
    "        \n",
    "        \n",
    "        # Compute initial delta:\n",
    "        # 1. Calculate the product of the prior and emission probabilities. This will be used to decode the first observation state.\n",
    "        # 2. Scale\n",
    "        init_ind = obs_st_dict[decode_observation_states[0]]\n",
    "        delta = np.multiply(prior_probs, emit_probs.T[init_ind,:])\n",
    "        #delta = delta / np.sum(delta)\n",
    "        #best_path[0] = path[0, np.argmax(delta)]\n",
    "        \n",
    "        print(\"obs: \", decode_observation_states)\n",
    "\n",
    "        # For each observation state to decode, select the hidden state sequence with the highest probability (i.e., Viterbi trellis)\n",
    "        for trellis_node in range(1, len(decode_observation_states)):\n",
    "\n",
    "            # TODO: comment the initialization, recursion, and termination steps\n",
    "    \n",
    "            current_obs = obs_st_dict[decode_observation_states[trellis_node]]\n",
    "            #print(\"delt: \", delta)\n",
    "            #print(\"trans: \", trans_probs.T)\n",
    "            #print(\"emit: \", emit_probs[:,current_obs])\n",
    "\n",
    "            product_of_delta_and_transition_emission = np.multiply(delta, trans_probs.T)\n",
    "            product_of_delta_and_transition_emission = np.multiply(product_of_delta_and_transition_emission.T, emit_probs[:,current_obs])\n",
    "            #print(\"prod: \", product_of_delta_and_transition_emission)\n",
    "\n",
    "            # Select the hidden state sequence with the maximum probability\n",
    "            max_hidden_ind = np.argmax(product_of_delta_and_transition_emission, axis=0) \n",
    "            max_hidden = np.max(product_of_delta_and_transition_emission, axis=0)\n",
    "            #print(\"prod: \", product_of_delta_and_transition_emission)\n",
    "            \n",
    "            path[trellis_node,:] = max_hidden_ind\n",
    "            #print(\"new path: \", path[trellis_node,:])\n",
    "            \n",
    "            #print(\"max hidden: \", max_hidden)\n",
    "            best_path[trellis_node - 1] = np.argmax(max_hidden)\n",
    "            print(\"best path: \", best_path)\n",
    "\n",
    "            # Update best path\n",
    "            #for hidden_state in range(len(self.hmm_object.hidden_states)):\n",
    "            #    hid_st_dict[hidden_state]\n",
    "            #    np.append(best_hidden_state_path, hidden_s)\n",
    "                #path.append(max_hidden_ind)\n",
    "            #    best_path[trellis_node] = max_hidden_ind\n",
    "            #    print(\"trellis: \", path[trellis_node - 1, max_hidden_ind])\n",
    "            #    best_path[trellis_node - 1] = path[trellis_node - 1, max_hidden_ind]\n",
    "                \n",
    "            \n",
    "            # Update delta and scale\n",
    "            delta = max_hidden\n",
    "            \n",
    "            #delta = np.multiply(max_hidden, emit_probs[current_obs,:])\n",
    "            #delta = delta / np.sum(delta)\n",
    "            \n",
    "            # Set best hidden state sequence in the best_path np.ndarray THEN copy the best_path to path\n",
    "\n",
    "        # Select the last hidden state, given the best path (i.e., maximum probability)\n",
    "        #best_hidden_state_path = np.array([])\n",
    "        print(\"final path: \", path)\n",
    "        for state in range(len(decode_observation_states) - 1, 0, -1):\n",
    "            best_path[state - 1] = path[state, int(best_path[state])]\n",
    "        best_hidden_state_path = [hid_st_dict[i] for i in best_path]\n",
    "        \n",
    "        return best_hidden_state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9581e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_case_one():\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    # index annotation observation_states=[i,j]    \n",
    "    observation_states = ['on-time','late'] \n",
    "\n",
    "    # index annotation hidden_states=[i,j]\n",
    "    hidden_states = ['no-traffic','traffic']\n",
    "\n",
    "    # PONDERING QUESTION: How would a user define/compute their own HMM instantiation inputs to decode the hidden states for their use case observations?\n",
    "    use_case_one_data = np.load('/Users/brysonchoy/Documents/hw6-hmm-viterbi/data/UserCase-One.npz')\n",
    "\n",
    "    # Instantiate submodule class models.HiddenMarkovModel with\n",
    "    # observation and hidden states and prior, transition, and emission probabilities.\n",
    "    use_case_one_hmm = HiddenMarkovModel(observation_states,\n",
    "                                         hidden_states,\n",
    "                      use_case_one_data['prior_probabilities'], # prior probabilities of hidden states in the order specified in the hidden_states list\n",
    "                      use_case_one_data['transition_probabilities'], # transition_probabilities[:,hidden_states[i]]\n",
    "                      use_case_one_data['emission_probabilities']) # emission_probabilities[hidden_states[i],:][:,observation_states[j]]\n",
    "    \n",
    "    # Instantiate submodule class models.ViterbiAlgorithm using the use case one HMM \n",
    "    use_case_one_viterbi = ViterbiAlgorithm(use_case_one_hmm)\n",
    "\n",
    "     # Check if use case one HiddenMarkovAlgorithm instance is inherited in the subsequent ViterbiAlgorithm instance\n",
    "    assert use_case_one_viterbi.hmm_object.observation_states == use_case_one_hmm.observation_states\n",
    "    assert use_case_one_viterbi.hmm_object.hidden_states == use_case_one_hmm.hidden_states\n",
    "\n",
    "    assert np.allclose(use_case_one_viterbi.hmm_object.prior_probabilities, use_case_one_hmm.prior_probabilities)\n",
    "    assert np.allclose(use_case_one_viterbi.hmm_object.transition_probabilities, use_case_one_hmm.transition_probabilities)\n",
    "    assert np.allclose(use_case_one_viterbi.hmm_object.emission_probabilities, use_case_one_hmm.emission_probabilities)\n",
    "\n",
    "    # TODO: Check HMM dimensions and ViterbiAlgorithm\n",
    "    \n",
    "    # Find the best hidden state path for our observation states\n",
    "    use_case_decoded_hidden_states = use_case_one_viterbi.best_hidden_state_sequence(use_case_one_data['observation_states'])\n",
    "    print(\"viterbi case: \", use_case_decoded_hidden_states)\n",
    "    \n",
    "    print(\"hidden: \", use_case_one_data['hidden_states'])\n",
    "    assert np.alltrue(use_case_decoded_hidden_states == use_case_one_data['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "9f68c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs:  ['on-time' 'on-time' 'late' 'late' 'late' 'on-time']\n",
      "best path:  [0. 0. 0. 0. 0. 0.]\n",
      "best path:  [0. 0. 0. 0. 0. 0.]\n",
      "best path:  [0. 0. 1. 0. 0. 0.]\n",
      "best path:  [0. 0. 1. 1. 0. 0.]\n",
      "best path:  [0. 0. 1. 1. 0. 0.]\n",
      "final path:  [[0. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 1.]]\n",
      "viterbi case:  ['no-traffic', 'no-traffic', 'traffic', 'traffic', 'traffic', 'no-traffic']\n",
      "hidden:  ['no-traffic' 'no-traffic' 'traffic' 'traffic' 'traffic' 'no-traffic']\n"
     ]
    }
   ],
   "source": [
    "test_user_case_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a1e4a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,:] = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f51eac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84b081a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.append(x,[4,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17eea4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1., 1., 4., 4., 4.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b3ecd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1., 1., 4., 4., 4., 8.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(tr, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cac2b5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [7 4]\n",
      " [8 8]\n",
      " [8 0]\n",
      " [9 8]\n",
      " [2 3]\n",
      " [3 8]\n",
      " [1 5]\n",
      " [4 3]\n",
      " [5 1]]\n",
      "[[4 3]]\n"
     ]
    }
   ],
   "source": [
    "test = np.random.choice(10,(10,2))\n",
    "test2 = np.random.choice(10,(1,2))\n",
    "print(test)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "78211a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0],\n",
       "       [ 6, 36]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(test2,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "59ce6678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 8, 8, 9, 3, 8, 5, 4, 5])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "896bd8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05280000000000001"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.132*0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "5df3184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 11, 16,  8, 17,  5, 11,  6,  7,  6])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "dfbf852d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.ones((test.shape[0])),np.ones((test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0bae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
