{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73a690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class HiddenMarkovModel:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_states: np.ndarray, hidden_states: np.ndarray, prior_probabilities: np.ndarray, transition_probabilities: np.ndarray, emission_probabilities: np.ndarray):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            observation_states (np.ndarray): _description_\n",
    "            hidden_states (np.ndarray): _description_\n",
    "            prior_probabilities (np.ndarray): _description_\n",
    "            transition_probabilities (np.ndarray): _description_\n",
    "            emission_probabilities (np.ndarray): _description_\n",
    "        \"\"\"             \n",
    "        self.observation_states = observation_states\n",
    "        self.observation_states_dict = {observation_state: observation_state_index \\\n",
    "                                  for observation_state_index, observation_state in enumerate(list(self.observation_states))}\n",
    "\n",
    "        self.hidden_states = hidden_states\n",
    "        self.hidden_states_dict = {hidden_state_index: hidden_state \\\n",
    "                                   for hidden_state_index, hidden_state in enumerate(list(self.hidden_states))}\n",
    "        \n",
    "\n",
    "        self.prior_probabilities= prior_probabilities\n",
    "        self.transition_probabilities = transition_probabilities\n",
    "        self.emission_probabilities = emission_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c655ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "class ViterbiAlgorithm:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"    \n",
    "\n",
    "    def __init__(self, hmm_object):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            hmm_object (_type_): _description_\n",
    "        \"\"\"              \n",
    "        self.hmm_object = hmm_object\n",
    "\n",
    "    def best_hidden_state_sequence(self, decode_observation_states: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            decode_observation_states (np.ndarray): _description_\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: _description_\n",
    "        \"\"\"        \n",
    "        \n",
    "        obs_st = self.hmm_object.observation_states\n",
    "        obs_st_dict = self.hmm_object.observation_states_dict\n",
    "        hid_st = self.hmm_object.hidden_states\n",
    "        hid_st_dict = self.hmm_object.hidden_states_dict\n",
    "        prior_probs = self.hmm_object.prior_probabilities\n",
    "        emit_probs = self.hmm_object.emission_probabilities\n",
    "        trans_probs = self.hmm_object.transition_probabilities\n",
    "\n",
    "        # Initialize path (i.e., np.arrays) to store the hidden sequence states returning the maximum probability\n",
    "        path = np.zeros((len(decode_observation_states), \n",
    "                         len(self.hmm_object.hidden_states)))\n",
    "        path[0,:] = [hidden_state_index for hidden_state_index in range(len(self.hmm_object.hidden_states))]\n",
    "\n",
    "        best_path = np.zeros(len(decode_observation_states))      \n",
    "        \n",
    "        # Compute initial delta:\n",
    "        # 1. Calculate the product of the prior and emission probabilities. This will be used to decode the first observation state.\n",
    "        # 2. Scale\n",
    "        init_ind = obs_st_dict[decode_observation_states[0]]\n",
    "        delta = np.multiply(prior_probs, emit_probs.T[init_ind,:])\n",
    "        delta = delta / np.sum(delta)\n",
    "\n",
    "        # For each observation state to decode, select the hidden state sequence with the highest probability (i.e., Viterbi trellis)\n",
    "        for trellis_node in range(1, len(decode_observation_states)):\n",
    "\n",
    "            # TODO: comment the initialization, recursion, and termination steps\n",
    "\n",
    "            current_obs = obs_st_dict[decode_observation_states[trellis_node]]\n",
    "\n",
    "            product_of_delta_and_transition_emission = np.multiply(delta, trans_probs.T)\n",
    "            product_of_delta_and_transition_emission = np.multiply(product_of_delta_and_transition_emission, emit_probs[:, current_obs])\n",
    "            \n",
    "\n",
    "            # Select the hidden state sequence with the maximum probability\n",
    "            max_hidden_ind = np.argmax(product_of_delta_and_transition_emission, axis=1) \n",
    "            max_hidden = np.max(product_of_delta_and_transition_emission, axis=1)\n",
    "            print(\"max: \", max_hidden_ind)\n",
    "            #path[trellis_node] = max_\n",
    "\n",
    "            # Update best path\n",
    "            for hidden_state in range(len(self.hmm_object.hidden_states)):\n",
    "                #path.append(max_hidden_ind)\n",
    "                best_path[trellis_node] = max_hidden_ind\n",
    "                print(\"trellis: \", path[trellis_node - 1, max_hidden_ind])\n",
    "                best_path[trellis_node - 1] = path[trellis_node - 1, max_hidden_ind]\n",
    "            \n",
    "            # Update delta and scale\n",
    "            delta = np.multiply(prior_probs, emit_probs.T[current_obs,:])\n",
    "            delta = delta / np.sum(delta)\n",
    "            \n",
    "            # Set best hidden state sequence in the best_path np.ndarray THEN copy the best_path to path\n",
    "\n",
    "        # Select the last hidden state, given the best path (i.e., maximum probability)\n",
    "\n",
    "        \n",
    "        best_hidden_state_path = np.array([])\n",
    "\n",
    "        return best_hidden_state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b49ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_case_one():\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    # index annotation observation_states=[i,j]    \n",
    "    observation_states = ['on-time','late'] \n",
    "\n",
    "    # index annotation hidden_states=[i,j]\n",
    "    hidden_states = ['no-traffic','traffic']\n",
    "\n",
    "    # PONDERING QUESTION: How would a user define/compute their own HMM instantiation inputs to decode the hidden states for their use case observations?\n",
    "    use_case_one_data = np.load('/Users/brysonchoy/Documents/hw6-hmm-viterbi/data/UserCase-One.npz')\n",
    "\n",
    "    # Instantiate submodule class models.HiddenMarkovModel with\n",
    "    # observation and hidden states and prior, transition, and emission probabilities.\n",
    "    use_case_one_hmm = HiddenMarkovModel(observation_states,\n",
    "                                         hidden_states,\n",
    "                      use_case_one_data['prior_probabilities'], # prior probabilities of hidden states in the order specified in the hidden_states list\n",
    "                      use_case_one_data['transition_probabilities'], # transition_probabilities[:,hidden_states[i]]\n",
    "                      use_case_one_data['emission_probabilities']) # emission_probabilities[hidden_states[i],:][:,observation_states[j]]\n",
    "    \n",
    "    # Instantiate submodule class models.ViterbiAlgorithm using the use case one HMM \n",
    "    use_case_one_viterbi = ViterbiAlgorithm(use_case_one_hmm)\n",
    "\n",
    "     # Check if use case one HiddenMarkovAlgorithm instance is inherited in the subsequent ViterbiAlgorithm instance\n",
    "    #assert use_case_one_viterbi.hmm_object.observation_states == use_case_one_hmm.observation_states\n",
    "    #assert use_case_one_viterbi.hmm_object.hidden_states == use_case_one_hmm.hidden_states\n",
    "\n",
    "    #assert np.allclose(use_case_one_viterbi.hmm_object.prior_probabilities, use_case_one_hmm.prior_probabilities)\n",
    "    #assert np.allclose(use_case_one_viterbi.hmm_object.transition_probabilities, use_case_one_hmm.transition_probabilities)\n",
    "    #assert np.allclose(use_case_one_viterbi.hmm_object.emission_probabilities, use_case_one_hmm.emission_probabilities)\n",
    "\n",
    "    # TODO: Check HMM dimensions and ViterbiAlgorithm\n",
    "    \n",
    "    # Find the best hidden state path for our observation states\n",
    "    use_case_decoded_hidden_states = use_case_one_viterbi.best_hidden_state_sequence(use_case_one_data['observation_states'])\n",
    "    print(\"viterbi case: \", use_case_decoded_hidden_states)\n",
    "\n",
    "    assert np.alltrue(use_case_decoded_hidden_states == use_case_one_data['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46fe2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  [0 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_user_case_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mtest_user_case_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m use_case_one_viterbi \u001b[38;5;241m=\u001b[39m ViterbiAlgorithm(use_case_one_hmm)\n\u001b[1;32m     24\u001b[0m  \u001b[38;5;66;03m# Check if use case one HiddenMarkovAlgorithm instance is inherited in the subsequent ViterbiAlgorithm instance\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#assert use_case_one_viterbi.hmm_object.observation_states == use_case_one_hmm.observation_states\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#assert use_case_one_viterbi.hmm_object.hidden_states == use_case_one_hmm.hidden_states\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Find the best hidden state path for our observation states\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m use_case_decoded_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43muse_case_one_viterbi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_hidden_state_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_case_one_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobservation_states\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mviterbi case: \u001b[39m\u001b[38;5;124m\"\u001b[39m, use_case_decoded_hidden_states)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39malltrue(use_case_decoded_hidden_states \u001b[38;5;241m==\u001b[39m use_case_one_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mViterbiAlgorithm.best_hidden_state_sequence\u001b[0;34m(self, decode_observation_states)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#path[trellis_node] = max_\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Update best path\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hidden_state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhmm_object\u001b[38;5;241m.\u001b[39mhidden_states)):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m#path.append(max_hidden_ind)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     best_path[trellis_node] \u001b[38;5;241m=\u001b[39m max_hidden_ind\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrellis: \u001b[39m\u001b[38;5;124m\"\u001b[39m, path[trellis_node \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, max_hidden_ind])\n\u001b[1;32m     69\u001b[0m     best_path[trellis_node \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m path[trellis_node \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, max_hidden_ind]\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "test_user_case_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791da68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
